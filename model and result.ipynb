{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .boolean { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .integer { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .string  { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "import scipy.stats as sps\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "from math import log10\n",
    "%matplotlib inline\n",
    "start_time = pd.datetime.now()\n",
    "import copy\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "#from categroy_encoders import TargetEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test=pd.read_csv('train_test.csv',index_col=0)\n",
    "OOT=pd.read_csv('ootdata.csv',index_col=0)\n",
    "oot=OOT[train_test.columns.to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split\n",
    "X=train_test.drop('Fraud', axis=1)\n",
    "#split the data into train and test\n",
    "y=train_test['Fraud'] #label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FDR(model,i):\n",
    "    prop=0.03\n",
    "    len_train=round(len(x_train)*prop)\n",
    "    len_test=round(len(x_test)*prop)\n",
    "    len_oot=round(len(oot)*prop)\n",
    "    pred_train=model.predict_proba(x_train)[:,1]\n",
    "    lg_train=pd.DataFrame({'Pred': pred_train, 'Fraud':y_train}).sort_values(by='Pred',ascending=False).head(len_train)\n",
    "    pred_test=model.predict_proba(x_test)[:,1]\n",
    "    lg_test=pd.DataFrame({'Pred': pred_test, 'Fraud':y_test}).sort_values(by='Pred',ascending=False).head(len_test)\n",
    "    pred_oot=model.predict_proba(oot.drop('Fraud',axis=1))[:,1]\n",
    "    lg_oot=pd.DataFrame({'Pred': pred_oot, 'Fraud':oot.Fraud}).sort_values(by='Pred',ascending=False).head(len_oot)\n",
    "    FDR_train=sum(lg_train.Fraud)/sum(y_train)\n",
    "    FDR_test=sum(lg_test.Fraud)/sum(y_test)\n",
    "    FDR_oot=sum(lg_oot.Fraud)/sum(oot.Fraud)\n",
    "    df_FDR=pd.DataFrame({'Train': FDR_train, 'Test':FDR_test,'OOT':FDR_oot},index=[i])\n",
    "    return (df_FDR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### baseline linear model (logistic regression)\n",
    "#### c=10, balanced is the best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logistic=pd.DataFrame(np.zeros(shape=(10,3)),columns=[\"Train\",\"Test\",\"OOT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set parameter \n",
    "C=1000\n",
    "model = LogisticRegression(C=C,solver=\"lbfgs\",class_weight='balanced',max_iter=5000)\n",
    "for i in range(10):\n",
    "    x_train,x_test,y_train,y_test= train_test_split(X,y,test_size=0.34,shuffle=True)\n",
    "    model.fit(x_train, y_train)\n",
    "    df_logistic.loc[i:i,'Train':'OOT']=FDR(model,i)\n",
    "\n",
    "df_logistic['Parameter']=\"c=1000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>OOT</th>\n",
       "      <th>Parameter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.737676</td>\n",
       "      <td>0.779264</td>\n",
       "      <td>0.491620</td>\n",
       "      <td>c=1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.732743</td>\n",
       "      <td>0.778146</td>\n",
       "      <td>0.497207</td>\n",
       "      <td>c=1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.746503</td>\n",
       "      <td>0.769492</td>\n",
       "      <td>0.536313</td>\n",
       "      <td>c=1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.741117</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.530726</td>\n",
       "      <td>c=1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.754783</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.541899</td>\n",
       "      <td>c=1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.763573</td>\n",
       "      <td>0.736486</td>\n",
       "      <td>0.553073</td>\n",
       "      <td>c=1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.763293</td>\n",
       "      <td>0.728873</td>\n",
       "      <td>0.564246</td>\n",
       "      <td>c=1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.753927</td>\n",
       "      <td>0.727891</td>\n",
       "      <td>0.486034</td>\n",
       "      <td>c=1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.757042</td>\n",
       "      <td>0.722408</td>\n",
       "      <td>0.502793</td>\n",
       "      <td>c=1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.771529</td>\n",
       "      <td>0.718121</td>\n",
       "      <td>0.502793</td>\n",
       "      <td>c=1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Train      Test       OOT Parameter\n",
       "9  0.737676  0.779264  0.491620    c=1000\n",
       "7  0.732743  0.778146  0.497207    c=1000\n",
       "4  0.746503  0.769492  0.536313    c=1000\n",
       "3  0.741117  0.760870  0.530726    c=1000\n",
       "1  0.754783  0.750000  0.541899    c=1000\n",
       "6  0.763573  0.736486  0.553073    c=1000\n",
       "2  0.763293  0.728873  0.564246    c=1000\n",
       "5  0.753927  0.727891  0.486034    c=1000\n",
       "8  0.757042  0.722408  0.502793    c=1000\n",
       "0  0.771529  0.718121  0.502793    c=1000"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_logistic.sort_values('Test',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>OOT</th>\n",
       "      <th>Parameter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.748700</td>\n",
       "      <td>0.762069</td>\n",
       "      <td>0.553073</td>\n",
       "      <td>c=100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.751323</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.497207</td>\n",
       "      <td>c=100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.760832</td>\n",
       "      <td>0.748276</td>\n",
       "      <td>0.541899</td>\n",
       "      <td>c=100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.744144</td>\n",
       "      <td>0.746795</td>\n",
       "      <td>0.480447</td>\n",
       "      <td>c=100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.752311</td>\n",
       "      <td>0.745399</td>\n",
       "      <td>0.564246</td>\n",
       "      <td>c=100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.743636</td>\n",
       "      <td>0.744479</td>\n",
       "      <td>0.530726</td>\n",
       "      <td>c=100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.761246</td>\n",
       "      <td>0.733564</td>\n",
       "      <td>0.547486</td>\n",
       "      <td>c=100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.756849</td>\n",
       "      <td>0.731449</td>\n",
       "      <td>0.530726</td>\n",
       "      <td>c=100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.756803</td>\n",
       "      <td>0.731183</td>\n",
       "      <td>0.519553</td>\n",
       "      <td>c=100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.757315</td>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.525140</td>\n",
       "      <td>c=100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Train      Test       OOT Parameter\n",
       "9  0.748700  0.762069  0.553073     c=100\n",
       "0  0.751323  0.750000  0.497207     c=100\n",
       "2  0.760832  0.748276  0.541899     c=100\n",
       "5  0.744144  0.746795  0.480447     c=100\n",
       "8  0.752311  0.745399  0.564246     c=100\n",
       "3  0.743636  0.744479  0.530726     c=100\n",
       "6  0.761246  0.733564  0.547486     c=100\n",
       "7  0.756849  0.731449  0.530726     c=100\n",
       "1  0.756803  0.731183  0.519553     c=100\n",
       "4  0.757315  0.706294  0.525140     c=100"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C=100\n",
    "model = LogisticRegression(C=C,solver=\"lbfgs\",class_weight='balanced',max_iter=5000)\n",
    "for i in range(10):\n",
    "    x_train,x_test,y_train,y_test= train_test_split(X,y,test_size=0.34,shuffle=True)\n",
    "    model.fit(x_train, y_train)\n",
    "    df_logistic.loc[i:i,'Train':'OOT']=FDR(model,i)\n",
    "\n",
    "df_logistic['Parameter']=\"c=100\"\n",
    "df_logistic.sort_values('Test',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>OOT</th>\n",
       "      <th>Parameter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.734024</td>\n",
       "      <td>0.809028</td>\n",
       "      <td>0.530726</td>\n",
       "      <td>c=10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.789831</td>\n",
       "      <td>0.519553</td>\n",
       "      <td>c=10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.742424</td>\n",
       "      <td>0.772894</td>\n",
       "      <td>0.530726</td>\n",
       "      <td>c=10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.748252</td>\n",
       "      <td>0.766102</td>\n",
       "      <td>0.547486</td>\n",
       "      <td>c=10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.743409</td>\n",
       "      <td>0.765101</td>\n",
       "      <td>0.497207</td>\n",
       "      <td>c=10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.742710</td>\n",
       "      <td>0.757042</td>\n",
       "      <td>0.486034</td>\n",
       "      <td>c=10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.745520</td>\n",
       "      <td>0.491620</td>\n",
       "      <td>c=10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.758497</td>\n",
       "      <td>0.733766</td>\n",
       "      <td>0.458101</td>\n",
       "      <td>c=10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.773038</td>\n",
       "      <td>0.718861</td>\n",
       "      <td>0.502793</td>\n",
       "      <td>c=10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.776430</td>\n",
       "      <td>0.717241</td>\n",
       "      <td>0.564246</td>\n",
       "      <td>c=10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Train      Test       OOT Parameter\n",
       "6  0.734024  0.809028  0.530726      c=10\n",
       "8  0.727273  0.789831  0.519553      c=10\n",
       "1  0.742424  0.772894  0.530726      c=10\n",
       "4  0.748252  0.766102  0.547486      c=10\n",
       "3  0.743409  0.765101  0.497207      c=10\n",
       "7  0.742710  0.757042  0.486034      c=10\n",
       "9  0.761905  0.745520  0.491620      c=10\n",
       "5  0.758497  0.733766  0.458101      c=10\n",
       "2  0.773038  0.718861  0.502793      c=10\n",
       "0  0.776430  0.717241  0.564246      c=10"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C=10\n",
    "model = LogisticRegression(C=C,solver=\"lbfgs\",class_weight='balanced',max_iter=5000)\n",
    "for i in range(10):\n",
    "    x_train,x_test,y_train,y_test= train_test_split(X,y,test_size=0.34,shuffle=True)\n",
    "    model.fit(x_train, y_train)\n",
    "    df_logistic.loc[i:i,'Train':'OOT']=FDR(model,i)\n",
    "\n",
    "df_logistic['Parameter']=\"c=10\"\n",
    "df_logistic.sort_values('Test',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>OOT</th>\n",
       "      <th>Parameter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.750859</td>\n",
       "      <td>0.778947</td>\n",
       "      <td>0.491620</td>\n",
       "      <td>c=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.752669</td>\n",
       "      <td>0.777049</td>\n",
       "      <td>0.502793</td>\n",
       "      <td>c=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.745363</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.463687</td>\n",
       "      <td>c=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.749546</td>\n",
       "      <td>0.762658</td>\n",
       "      <td>0.480447</td>\n",
       "      <td>c=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.740103</td>\n",
       "      <td>0.755245</td>\n",
       "      <td>0.491620</td>\n",
       "      <td>c=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.759162</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.508380</td>\n",
       "      <td>c=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.760360</td>\n",
       "      <td>0.740385</td>\n",
       "      <td>0.547486</td>\n",
       "      <td>c=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.770053</td>\n",
       "      <td>0.728758</td>\n",
       "      <td>0.486034</td>\n",
       "      <td>c=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.780576</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.497207</td>\n",
       "      <td>c=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.786311</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.513966</td>\n",
       "      <td>c=1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Train      Test       OOT Parameter\n",
       "7  0.750859  0.778947  0.491620       c=1\n",
       "1  0.752669  0.777049  0.502793       c=1\n",
       "0  0.745363  0.773723  0.463687       c=1\n",
       "5  0.749546  0.762658  0.480447       c=1\n",
       "3  0.740103  0.755245  0.491620       c=1\n",
       "2  0.759162  0.755102  0.508380       c=1\n",
       "8  0.760360  0.740385  0.547486       c=1\n",
       "6  0.770053  0.728758  0.486034       c=1\n",
       "9  0.780576  0.720257  0.497207       c=1\n",
       "4  0.786311  0.716418  0.513966       c=1"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C=1\n",
    "model = LogisticRegression(C=C,solver=\"lbfgs\",class_weight='balanced',max_iter=5000)\n",
    "for i in range(10):\n",
    "    x_train,x_test,y_train,y_test= train_test_split(X,y,test_size=0.34,shuffle=True)\n",
    "    model.fit(x_train, y_train)\n",
    "    df_logistic.loc[i:i,'Train':'OOT']=FDR(model,i)\n",
    "\n",
    "df_logistic['Parameter']=\"c=1\"\n",
    "df_logistic.sort_values('Test',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>OOT</th>\n",
       "      <th>Parameter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.727592</td>\n",
       "      <td>0.771812</td>\n",
       "      <td>0.340782</td>\n",
       "      <td>c=10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.717117</td>\n",
       "      <td>0.766026</td>\n",
       "      <td>0.351955</td>\n",
       "      <td>c=10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.729310</td>\n",
       "      <td>0.759582</td>\n",
       "      <td>0.363128</td>\n",
       "      <td>c=10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.740675</td>\n",
       "      <td>0.730263</td>\n",
       "      <td>0.368715</td>\n",
       "      <td>c=10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.726786</td>\n",
       "      <td>0.713355</td>\n",
       "      <td>0.307263</td>\n",
       "      <td>c=10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.742504</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.363128</td>\n",
       "      <td>c=10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.735537</td>\n",
       "      <td>0.709924</td>\n",
       "      <td>0.346369</td>\n",
       "      <td>c=10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.736041</td>\n",
       "      <td>0.706522</td>\n",
       "      <td>0.346369</td>\n",
       "      <td>c=10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.745201</td>\n",
       "      <td>0.697279</td>\n",
       "      <td>0.351955</td>\n",
       "      <td>c=10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.751342</td>\n",
       "      <td>0.675325</td>\n",
       "      <td>0.351955</td>\n",
       "      <td>c=10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Train      Test       OOT Parameter\n",
       "5  0.727592  0.771812  0.340782      c=10\n",
       "0  0.717117  0.766026  0.351955      c=10\n",
       "2  0.729310  0.759582  0.363128      c=10\n",
       "6  0.740675  0.730263  0.368715      c=10\n",
       "7  0.726786  0.713355  0.307263      c=10\n",
       "4  0.742504  0.710000  0.363128      c=10\n",
       "8  0.735537  0.709924  0.346369      c=10\n",
       "3  0.736041  0.706522  0.346369      c=10\n",
       "9  0.745201  0.697279  0.351955      c=10\n",
       "1  0.751342  0.675325  0.351955      c=10"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C=10\n",
    "model = LogisticRegression(C=C,solver=\"lbfgs\",max_iter=5000)\n",
    "for i in range(10):\n",
    "    x_train,x_test,y_train,y_test= train_test_split(X,y,test_size=0.34,shuffle=True)\n",
    "    model.fit(x_train, y_train)\n",
    "    df_logistic.loc[i:i,'Train':'OOT']=FDR(model,i)\n",
    "\n",
    "df_logistic['Parameter']=\"c=10\"\n",
    "df_logistic.sort_values('Test',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "### n_estimators=100 , max_depth=10 , max_features=20 is the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf=pd.DataFrame(np.zeros(shape=(10,3)),columns=[\"Train\",\"Test\",\"OOT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators=100\n",
    "max_depth=10\n",
    "max_features=20\n",
    "model_rf=RandomForestClassifier(oob_score=True,n_estimators=n_estimators,max_depth=max_depth,max_features=max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    x_train,x_test,y_train,y_test= train_test_split(X,y,test_size=0.34,shuffle=True)\n",
    "    model_rf.fit(x_train, y_train)\n",
    "    df_rf.loc[i:i,'Train':'OOT']=FDR(model_rf,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>OOT</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.928070</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.924915</td>\n",
       "      <td>0.882562</td>\n",
       "      <td>0.608939</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.936015</td>\n",
       "      <td>0.881250</td>\n",
       "      <td>0.608939</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.935154</td>\n",
       "      <td>0.875445</td>\n",
       "      <td>0.603352</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.933105</td>\n",
       "      <td>0.869718</td>\n",
       "      <td>0.620112</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.919521</td>\n",
       "      <td>0.869258</td>\n",
       "      <td>0.620112</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.927586</td>\n",
       "      <td>0.867596</td>\n",
       "      <td>0.642458</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.917857</td>\n",
       "      <td>0.863192</td>\n",
       "      <td>0.620112</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.930435</td>\n",
       "      <td>0.863014</td>\n",
       "      <td>0.636872</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.929453</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.614525</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Train      Test       OOT  n_estimators  max_depth  max_features\n",
       "1  0.928070  0.888889  0.625698           100         10            20\n",
       "4  0.924915  0.882562  0.608939           100         10            20\n",
       "0  0.936015  0.881250  0.608939           100         10            20\n",
       "5  0.935154  0.875445  0.603352           100         10            20\n",
       "3  0.933105  0.869718  0.620112           100         10            20\n",
       "6  0.919521  0.869258  0.620112           100         10            20\n",
       "2  0.927586  0.867596  0.642458           100         10            20\n",
       "8  0.917857  0.863192  0.620112           100         10            20\n",
       "7  0.930435  0.863014  0.636872           100         10            20\n",
       "9  0.929453  0.830000  0.614525           100         10            20"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf['n_estimators']=n_estimators\n",
    "df_rf['max_depth']=max_depth\n",
    "df_rf['max_features']=max_features\n",
    "df_rf.sort_values('Test',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators=60\n",
    "max_depth=15\n",
    "max_features=30\n",
    "model_rf=RandomForestClassifier(oob_score=True,n_estimators=n_estimators,max_depth=max_depth,max_features=max_features)\n",
    "for i in range(10):\n",
    "    x_train,x_test,y_train,y_test= train_test_split(X,y,test_size=0.34,shuffle=True)\n",
    "    model_rf.fit(x_train, y_train)\n",
    "    df_rf.loc[i:i,'Train':'OOT']=FDR(model_rf,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>OOT</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.986418</td>\n",
       "      <td>0.920863</td>\n",
       "      <td>0.608939</td>\n",
       "      <td>60</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.989418</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.547486</td>\n",
       "      <td>60</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.989510</td>\n",
       "      <td>0.894915</td>\n",
       "      <td>0.586592</td>\n",
       "      <td>60</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.982609</td>\n",
       "      <td>0.893836</td>\n",
       "      <td>0.614525</td>\n",
       "      <td>60</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.989601</td>\n",
       "      <td>0.889655</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>60</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.991135</td>\n",
       "      <td>0.884488</td>\n",
       "      <td>0.614525</td>\n",
       "      <td>60</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.992844</td>\n",
       "      <td>0.879870</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>60</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.998273</td>\n",
       "      <td>0.878472</td>\n",
       "      <td>0.575419</td>\n",
       "      <td>60</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.986577</td>\n",
       "      <td>0.878229</td>\n",
       "      <td>0.547486</td>\n",
       "      <td>60</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.978188</td>\n",
       "      <td>0.878229</td>\n",
       "      <td>0.603352</td>\n",
       "      <td>60</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Train      Test       OOT  n_estimators  max_depth  max_features\n",
       "6  0.986418  0.920863  0.608939            60         15            30\n",
       "9  0.989418  0.900000  0.547486            60         15            30\n",
       "1  0.989510  0.894915  0.586592            60         15            30\n",
       "2  0.982609  0.893836  0.614525            60         15            30\n",
       "3  0.989601  0.889655  0.581006            60         15            30\n",
       "5  0.991135  0.884488  0.614525            60         15            30\n",
       "0  0.992844  0.879870  0.581006            60         15            30\n",
       "7  0.998273  0.878472  0.575419            60         15            30\n",
       "4  0.986577  0.878229  0.547486            60         15            30\n",
       "8  0.978188  0.878229  0.603352            60         15            30"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf['n_estimators']=n_estimators\n",
    "df_rf['max_depth']=max_depth\n",
    "df_rf['max_features']=max_features\n",
    "df_rf.sort_values('Test',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators=100\n",
    "max_depth=20\n",
    "max_features=20\n",
    "model_rf=RandomForestClassifier(oob_score=True,n_estimators=n_estimators,max_depth=max_depth,max_features=max_features)\n",
    "for i in range(10):\n",
    "    x_train,x_test,y_train,y_test= train_test_split(X,y,test_size=0.34,shuffle=True)\n",
    "    model_rf.fit(x_train, y_train)\n",
    "    df_rf.loc[i:i,'Train':'OOT']=FDR(model_rf,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>OOT</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>0.631285</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933824</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933798</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933798</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.920792</td>\n",
       "      <td>0.608939</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.920290</td>\n",
       "      <td>0.603352</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.913183</td>\n",
       "      <td>0.620112</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909408</td>\n",
       "      <td>0.620112</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.902280</td>\n",
       "      <td>0.620112</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.608939</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train      Test       OOT  n_estimators  max_depth  max_features\n",
       "1    1.0  0.938462  0.631285           100         20            20\n",
       "0    1.0  0.933824  0.625698           100         20            20\n",
       "8    1.0  0.933798  0.625698           100         20            20\n",
       "9    1.0  0.933798  0.625698           100         20            20\n",
       "7    1.0  0.920792  0.608939           100         20            20\n",
       "3    1.0  0.920290  0.603352           100         20            20\n",
       "4    1.0  0.913183  0.620112           100         20            20\n",
       "2    1.0  0.909408  0.620112           100         20            20\n",
       "5    1.0  0.902280  0.620112           100         20            20\n",
       "6    1.0  0.896104  0.608939           100         20            20"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf['n_estimators']=n_estimators\n",
    "df_rf['max_depth']=max_depth\n",
    "df_rf['max_features']=max_features\n",
    "df_rf.sort_values('Test',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### boosted tree\n",
    "### didn't perform better than random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xgb=pd.DataFrame(np.zeros(shape=(10,3)),columns=[\"Train\",\"Test\",\"OOT\"])\n",
    "\n",
    "n_estimators=600\n",
    "learning_rate=0.1\n",
    "max_depth=5\n",
    "\n",
    "model_xgb = xgb.XGBClassifier(n_estimators=n_estimators,max_depth=max_depth,learning_rate=learning_rate)\n",
    "\n",
    "for i in range(10):\n",
    "    x_train,x_test,y_train,y_test= train_test_split(X,y,test_size=0.34,shuffle=True)\n",
    "    model_xgb.fit(x_train, y_train)\n",
    "    df_xgb.loc[i:i,'Train':'OOT']=FDR(model_xgb,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xgb['n_estimators']=n_estimators\n",
    "df_xgb['max_depth']=max_depth\n",
    "df_xgb['learning_rate']=learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>OOT</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950570</td>\n",
       "      <td>0.564246</td>\n",
       "      <td>600</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.952229</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>600</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.936877</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>600</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.952830</td>\n",
       "      <td>0.592179</td>\n",
       "      <td>600</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.952862</td>\n",
       "      <td>0.525140</td>\n",
       "      <td>600</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.942675</td>\n",
       "      <td>0.603352</td>\n",
       "      <td>600</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.924731</td>\n",
       "      <td>0.592179</td>\n",
       "      <td>600</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.923323</td>\n",
       "      <td>0.558659</td>\n",
       "      <td>600</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.491620</td>\n",
       "      <td>600</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.948220</td>\n",
       "      <td>0.586592</td>\n",
       "      <td>600</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train      Test       OOT  n_estimators  max_depth  learning_rate\n",
       "0    1.0  0.950570  0.564246           600          5            0.1\n",
       "1    1.0  0.952229  0.581006           600          5            0.1\n",
       "2    1.0  0.936877  0.569832           600          5            0.1\n",
       "3    1.0  0.952830  0.592179           600          5            0.1\n",
       "4    1.0  0.952862  0.525140           600          5            0.1\n",
       "5    1.0  0.942675  0.603352           600          5            0.1\n",
       "6    1.0  0.924731  0.592179           600          5            0.1\n",
       "7    1.0  0.923323  0.558659           600          5            0.1\n",
       "8    1.0  0.969697  0.491620           600          5            0.1\n",
       "9    1.0  0.948220  0.586592           600          5            0.1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators=500\n",
    "learning_rate=1\n",
    "max_depth=3\n",
    "\n",
    "model_xgb = xgb.XGBClassifier(n_estimators=n_estimators,max_depth=max_depth,learning_rate=learning_rate)\n",
    "\n",
    "for i in range(10):\n",
    "    x_train,x_test,y_train,y_test= train_test_split(X,y,test_size=0.34,shuffle=True)\n",
    "    model_xgb.fit(x_train, y_train)\n",
    "    df_xgb.loc[i:i,'Train':'OOT']=FDR(model_xgb,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>OOT</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.951049</td>\n",
       "      <td>0.536313</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.932515</td>\n",
       "      <td>0.385475</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.934426</td>\n",
       "      <td>0.368715</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.497207</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.920382</td>\n",
       "      <td>0.463687</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.915254</td>\n",
       "      <td>0.424581</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.941818</td>\n",
       "      <td>0.480447</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.920266</td>\n",
       "      <td>0.558659</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.407821</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.957295</td>\n",
       "      <td>0.424581</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train      Test       OOT  n_estimators  max_depth  learning_rate\n",
       "0    1.0  0.951049  0.536313           500          3              1\n",
       "1    1.0  0.932515  0.385475           500          3              1\n",
       "2    1.0  0.934426  0.368715           500          3              1\n",
       "3    1.0  0.923077  0.497207           500          3              1\n",
       "4    1.0  0.920382  0.463687           500          3              1\n",
       "5    1.0  0.915254  0.424581           500          3              1\n",
       "6    1.0  0.941818  0.480447           500          3              1\n",
       "7    1.0  0.920266  0.558659           500          3              1\n",
       "8    1.0  0.903226  0.407821           500          3              1\n",
       "9    1.0  0.957295  0.424581           500          3              1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xgb['n_estimators']=n_estimators\n",
    "df_xgb['max_depth']=max_depth\n",
    "df_xgb['learning_rate']=learning_rate\n",
    "df_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators=1000\n",
    "learning_rate=0.01\n",
    "max_depth=6\n",
    "\n",
    "model_xgb = xgb.XGBClassifier(n_estimators=n_estimators,max_depth=max_depth,learning_rate=learning_rate)\n",
    "\n",
    "for i in range(10):\n",
    "    x_train,x_test,y_train,y_test= train_test_split(X,y,test_size=0.34,shuffle=True)\n",
    "    model_xgb.fit(x_train, y_train)\n",
    "    df_xgb.loc[i:i,'Train':'OOT']=FDR(model_xgb,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>OOT</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.996503</td>\n",
       "      <td>0.935593</td>\n",
       "      <td>0.631285</td>\n",
       "      <td>1000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.993139</td>\n",
       "      <td>0.911972</td>\n",
       "      <td>0.636872</td>\n",
       "      <td>1000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.994755</td>\n",
       "      <td>0.911864</td>\n",
       "      <td>0.525140</td>\n",
       "      <td>1000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.994845</td>\n",
       "      <td>0.901754</td>\n",
       "      <td>0.653631</td>\n",
       "      <td>1000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.989455</td>\n",
       "      <td>0.916107</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>1000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.996558</td>\n",
       "      <td>0.916084</td>\n",
       "      <td>0.642458</td>\n",
       "      <td>1000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.998291</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.620112</td>\n",
       "      <td>1000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.994652</td>\n",
       "      <td>0.872549</td>\n",
       "      <td>0.597765</td>\n",
       "      <td>1000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.994652</td>\n",
       "      <td>0.950980</td>\n",
       "      <td>0.575419</td>\n",
       "      <td>1000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.954704</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>1000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Train      Test       OOT  n_estimators  max_depth  learning_rate\n",
       "0  0.996503  0.935593  0.631285          1000          6           0.01\n",
       "1  0.993139  0.911972  0.636872          1000          6           0.01\n",
       "2  0.994755  0.911864  0.525140          1000          6           0.01\n",
       "3  0.994845  0.901754  0.653631          1000          6           0.01\n",
       "4  0.989455  0.916107  0.581006          1000          6           0.01\n",
       "5  0.996558  0.916084  0.642458          1000          6           0.01\n",
       "6  0.998291  0.936170  0.620112          1000          6           0.01\n",
       "7  0.994652  0.872549  0.597765          1000          6           0.01\n",
       "8  0.994652  0.950980  0.575419          1000          6           0.01\n",
       "9  0.991379  0.954704  0.625698          1000          6           0.01"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xgb['n_estimators']=n_estimators\n",
    "df_xgb['max_depth']=max_depth\n",
    "df_xgb['learning_rate']=learning_rate\n",
    "df_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xgb=pd.DataFrame(np.zeros(shape=(10,3)),columns=[\"Train\",\"Test\",\"OOT\"])\n",
    "\n",
    "n_estimators=800\n",
    "learning_rate=0.001\n",
    "max_depth=4\n",
    "\n",
    "model_xgb = xgb.XGBClassifier(n_estimators=n_estimators,max_depth=max_depth,learning_rate=learning_rate)\n",
    "\n",
    "for i in range(10):\n",
    "    x_train,x_test,y_train,y_test= train_test_split(X,y,test_size=0.34,shuffle=True)\n",
    "    model_xgb.fit(x_train, y_train)\n",
    "    df_xgb.loc[i:i,'Train':'OOT']=FDR(model_xgb,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>OOT</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.756614</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>0.519553</td>\n",
       "      <td>800</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.705151</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.391061</td>\n",
       "      <td>800</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.778169</td>\n",
       "      <td>0.755853</td>\n",
       "      <td>0.586592</td>\n",
       "      <td>800</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.740484</td>\n",
       "      <td>0.592179</td>\n",
       "      <td>800</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.758319</td>\n",
       "      <td>0.722973</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>800</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.730298</td>\n",
       "      <td>0.658784</td>\n",
       "      <td>0.446927</td>\n",
       "      <td>800</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.808244</td>\n",
       "      <td>0.763754</td>\n",
       "      <td>0.603352</td>\n",
       "      <td>800</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.761649</td>\n",
       "      <td>0.705502</td>\n",
       "      <td>0.547486</td>\n",
       "      <td>800</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.785124</td>\n",
       "      <td>0.687023</td>\n",
       "      <td>0.597765</td>\n",
       "      <td>800</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.765018</td>\n",
       "      <td>0.707641</td>\n",
       "      <td>0.631285</td>\n",
       "      <td>800</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Train      Test       OOT  n_estimators  max_depth  learning_rate\n",
       "0  0.756614  0.706667  0.519553           800          4          0.001\n",
       "1  0.705151  0.657895  0.391061           800          4          0.001\n",
       "2  0.778169  0.755853  0.586592           800          4          0.001\n",
       "3  0.794118  0.740484  0.592179           800          4          0.001\n",
       "4  0.758319  0.722973  0.569832           800          4          0.001\n",
       "5  0.730298  0.658784  0.446927           800          4          0.001\n",
       "6  0.808244  0.763754  0.603352           800          4          0.001\n",
       "7  0.761649  0.705502  0.547486           800          4          0.001\n",
       "8  0.785124  0.687023  0.597765           800          4          0.001\n",
       "9  0.765018  0.707641  0.631285           800          4          0.001"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xgb['n_estimators']=n_estimators\n",
    "df_xgb['max_depth']=max_depth\n",
    "df_xgb['learning_rate']=learning_rate\n",
    "df_xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Random Forest model on train,test,oot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=10, max_features=20,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=True, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators=100\n",
    "max_depth=10\n",
    "max_features=20\n",
    "model_rf=RandomForestClassifier(oob_score=True,n_estimators=n_estimators,max_depth=max_depth,max_features=max_features)\n",
    "x_train,x_test,y_train,y_test= train_test_split(X,y,test_size=0.34,shuffle=True)\n",
    "model_rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### trainning\n",
    "prop=0.2\n",
    "pred_train=model_rf.predict_proba(x_train)[:,1]\n",
    "result_train=pd.DataFrame({'Pred': pred_train, 'Fraud':y_train}).sort_values(by='Pred',ascending=False)\n",
    "result_train_part=result_train.head(round(len(x_train)*prop))\n",
    "    \n",
    "bin_df=pd.DataFrame(np.zeros(shape=(20,10)),columns=[\"Population\",\"# Records\",\"# Goods\",\"# Bads\",\"% Goods\",\"% Bads\",\n",
    "                                                   \"Total # Records\",\"Cum Goods\",\"Cum Bads\",\"FPR\"])\n",
    "cum_df=pd.DataFrame(np.zeros(shape=(20,3)),columns=[\"% Good\",\"% Bad(FDR)\",\"KS\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_qcut = result_train_part.copy().reset_index(drop=True).reset_index()\n",
    "bin_qcut['qcut_group'] = pd.qcut(bin_qcut['index'], 20,labels=False)\n",
    "population=range(1,21,1)\n",
    "bin_df[\"Population\"]=population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_records=bin_qcut.groupby('qcut_group').size()\n",
    "bin_df['# Records']=n_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bads=bin_qcut.groupby('qcut_group')['Fraud'].sum()\n",
    "bin_df['# Bads']=n_bads\n",
    "n_goods=n_records-n_bads\n",
    "bin_df['# Goods']=n_goods\n",
    "bin_df['% Goods']=round(n_goods/n_records*100,2)\n",
    "bin_df['% Bads']=round(n_bads/n_records*100,2)\n",
    "bin_df[\"Total # Records\"]=np.cumsum(n_records)  \n",
    "bin_df[\"Cum Goods\"]=np.cumsum(n_goods)\n",
    "bin_df[\"Cum Bads\"]=np.cumsum(n_bads)\n",
    "bin_df[\"FPR\"]=round(bin_df[\"Cum Goods\"]/bin_df[\"Cum Bads\"],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "FDR_train_bad=[]\n",
    "FDR_train_good=[]\n",
    "for p in population:\n",
    "    result_train_p=result_train.head(round(len(x_train)*p*0.01))\n",
    "    bad=sum(result_train_p.Fraud)/sum(y_train)\n",
    "    good=(len(result_train_p)-sum(result_train_p.Fraud))/(len(y_train)-sum(y_train))\n",
    "    FDR_train_bad.append(round(bad*100,2))\n",
    "    FDR_train_good.append(round(good*100,2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_df['% Bad(FDR)']= FDR_train_bad\n",
    "cum_df['% Good']=FDR_train_good\n",
    "cum_df['KS']=cum_df['% Bad(FDR)']-cum_df['% Good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_table=pd.concat([bin_df,cum_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Population</th>\n",
       "      <th># Records</th>\n",
       "      <th># Goods</th>\n",
       "      <th># Bads</th>\n",
       "      <th>% Goods</th>\n",
       "      <th>% Bads</th>\n",
       "      <th>Total # Records</th>\n",
       "      <th>Cum Goods</th>\n",
       "      <th>Cum Bads</th>\n",
       "      <th>FPR</th>\n",
       "      <th>% Good</th>\n",
       "      <th>% Bad(FDR)</th>\n",
       "      <th>KS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>532</td>\n",
       "      <td>44</td>\n",
       "      <td>488</td>\n",
       "      <td>8.27</td>\n",
       "      <td>91.73</td>\n",
       "      <td>532</td>\n",
       "      <td>44</td>\n",
       "      <td>488</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.08</td>\n",
       "      <td>85.61</td>\n",
       "      <td>85.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>531</td>\n",
       "      <td>494</td>\n",
       "      <td>37</td>\n",
       "      <td>93.03</td>\n",
       "      <td>6.97</td>\n",
       "      <td>1063</td>\n",
       "      <td>538</td>\n",
       "      <td>525</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.02</td>\n",
       "      <td>92.11</td>\n",
       "      <td>91.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>531</td>\n",
       "      <td>529</td>\n",
       "      <td>2</td>\n",
       "      <td>99.62</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1594</td>\n",
       "      <td>1067</td>\n",
       "      <td>527</td>\n",
       "      <td>2.02</td>\n",
       "      <td>2.03</td>\n",
       "      <td>92.46</td>\n",
       "      <td>90.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>531</td>\n",
       "      <td>525</td>\n",
       "      <td>6</td>\n",
       "      <td>98.87</td>\n",
       "      <td>1.13</td>\n",
       "      <td>2125</td>\n",
       "      <td>1592</td>\n",
       "      <td>533</td>\n",
       "      <td>2.99</td>\n",
       "      <td>3.03</td>\n",
       "      <td>93.51</td>\n",
       "      <td>90.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>532</td>\n",
       "      <td>531</td>\n",
       "      <td>1</td>\n",
       "      <td>99.81</td>\n",
       "      <td>0.19</td>\n",
       "      <td>2657</td>\n",
       "      <td>2123</td>\n",
       "      <td>534</td>\n",
       "      <td>3.98</td>\n",
       "      <td>4.04</td>\n",
       "      <td>93.68</td>\n",
       "      <td>89.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>531</td>\n",
       "      <td>531</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3188</td>\n",
       "      <td>2654</td>\n",
       "      <td>534</td>\n",
       "      <td>4.97</td>\n",
       "      <td>5.05</td>\n",
       "      <td>93.68</td>\n",
       "      <td>88.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>531</td>\n",
       "      <td>530</td>\n",
       "      <td>1</td>\n",
       "      <td>99.81</td>\n",
       "      <td>0.19</td>\n",
       "      <td>3719</td>\n",
       "      <td>3184</td>\n",
       "      <td>535</td>\n",
       "      <td>5.95</td>\n",
       "      <td>6.06</td>\n",
       "      <td>93.86</td>\n",
       "      <td>87.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>531</td>\n",
       "      <td>528</td>\n",
       "      <td>3</td>\n",
       "      <td>99.44</td>\n",
       "      <td>0.56</td>\n",
       "      <td>4250</td>\n",
       "      <td>3712</td>\n",
       "      <td>538</td>\n",
       "      <td>6.90</td>\n",
       "      <td>7.06</td>\n",
       "      <td>94.39</td>\n",
       "      <td>87.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>531</td>\n",
       "      <td>530</td>\n",
       "      <td>1</td>\n",
       "      <td>99.81</td>\n",
       "      <td>0.19</td>\n",
       "      <td>4781</td>\n",
       "      <td>4242</td>\n",
       "      <td>539</td>\n",
       "      <td>7.87</td>\n",
       "      <td>8.07</td>\n",
       "      <td>94.56</td>\n",
       "      <td>86.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>532</td>\n",
       "      <td>532</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5313</td>\n",
       "      <td>4774</td>\n",
       "      <td>539</td>\n",
       "      <td>8.86</td>\n",
       "      <td>9.08</td>\n",
       "      <td>94.56</td>\n",
       "      <td>85.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>531</td>\n",
       "      <td>525</td>\n",
       "      <td>6</td>\n",
       "      <td>98.87</td>\n",
       "      <td>1.13</td>\n",
       "      <td>5844</td>\n",
       "      <td>5299</td>\n",
       "      <td>545</td>\n",
       "      <td>9.72</td>\n",
       "      <td>10.08</td>\n",
       "      <td>95.61</td>\n",
       "      <td>85.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>531</td>\n",
       "      <td>529</td>\n",
       "      <td>2</td>\n",
       "      <td>99.62</td>\n",
       "      <td>0.38</td>\n",
       "      <td>6375</td>\n",
       "      <td>5828</td>\n",
       "      <td>547</td>\n",
       "      <td>10.65</td>\n",
       "      <td>11.09</td>\n",
       "      <td>95.96</td>\n",
       "      <td>84.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>531</td>\n",
       "      <td>529</td>\n",
       "      <td>2</td>\n",
       "      <td>99.62</td>\n",
       "      <td>0.38</td>\n",
       "      <td>6906</td>\n",
       "      <td>6357</td>\n",
       "      <td>549</td>\n",
       "      <td>11.58</td>\n",
       "      <td>12.10</td>\n",
       "      <td>96.32</td>\n",
       "      <td>84.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>531</td>\n",
       "      <td>528</td>\n",
       "      <td>3</td>\n",
       "      <td>99.44</td>\n",
       "      <td>0.56</td>\n",
       "      <td>7437</td>\n",
       "      <td>6885</td>\n",
       "      <td>552</td>\n",
       "      <td>12.47</td>\n",
       "      <td>13.10</td>\n",
       "      <td>96.84</td>\n",
       "      <td>83.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>532</td>\n",
       "      <td>532</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7969</td>\n",
       "      <td>7417</td>\n",
       "      <td>552</td>\n",
       "      <td>13.44</td>\n",
       "      <td>14.11</td>\n",
       "      <td>96.84</td>\n",
       "      <td>82.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>531</td>\n",
       "      <td>530</td>\n",
       "      <td>1</td>\n",
       "      <td>99.81</td>\n",
       "      <td>0.19</td>\n",
       "      <td>8500</td>\n",
       "      <td>7947</td>\n",
       "      <td>553</td>\n",
       "      <td>14.37</td>\n",
       "      <td>15.12</td>\n",
       "      <td>97.02</td>\n",
       "      <td>81.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>531</td>\n",
       "      <td>531</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9031</td>\n",
       "      <td>8478</td>\n",
       "      <td>553</td>\n",
       "      <td>15.33</td>\n",
       "      <td>16.13</td>\n",
       "      <td>97.02</td>\n",
       "      <td>80.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>531</td>\n",
       "      <td>530</td>\n",
       "      <td>1</td>\n",
       "      <td>99.81</td>\n",
       "      <td>0.19</td>\n",
       "      <td>9562</td>\n",
       "      <td>9008</td>\n",
       "      <td>554</td>\n",
       "      <td>16.26</td>\n",
       "      <td>17.14</td>\n",
       "      <td>97.19</td>\n",
       "      <td>80.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>531</td>\n",
       "      <td>530</td>\n",
       "      <td>1</td>\n",
       "      <td>99.81</td>\n",
       "      <td>0.19</td>\n",
       "      <td>10093</td>\n",
       "      <td>9538</td>\n",
       "      <td>555</td>\n",
       "      <td>17.19</td>\n",
       "      <td>18.15</td>\n",
       "      <td>97.37</td>\n",
       "      <td>79.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>532</td>\n",
       "      <td>532</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10625</td>\n",
       "      <td>10070</td>\n",
       "      <td>555</td>\n",
       "      <td>18.14</td>\n",
       "      <td>19.16</td>\n",
       "      <td>97.37</td>\n",
       "      <td>78.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Population  # Records  # Goods  # Bads  % Goods  % Bads  Total # Records  \\\n",
       "0            1        532       44     488     8.27   91.73              532   \n",
       "1            2        531      494      37    93.03    6.97             1063   \n",
       "2            3        531      529       2    99.62    0.38             1594   \n",
       "3            4        531      525       6    98.87    1.13             2125   \n",
       "4            5        532      531       1    99.81    0.19             2657   \n",
       "5            6        531      531       0   100.00    0.00             3188   \n",
       "6            7        531      530       1    99.81    0.19             3719   \n",
       "7            8        531      528       3    99.44    0.56             4250   \n",
       "8            9        531      530       1    99.81    0.19             4781   \n",
       "9           10        532      532       0   100.00    0.00             5313   \n",
       "10          11        531      525       6    98.87    1.13             5844   \n",
       "11          12        531      529       2    99.62    0.38             6375   \n",
       "12          13        531      529       2    99.62    0.38             6906   \n",
       "13          14        531      528       3    99.44    0.56             7437   \n",
       "14          15        532      532       0   100.00    0.00             7969   \n",
       "15          16        531      530       1    99.81    0.19             8500   \n",
       "16          17        531      531       0   100.00    0.00             9031   \n",
       "17          18        531      530       1    99.81    0.19             9562   \n",
       "18          19        531      530       1    99.81    0.19            10093   \n",
       "19          20        532      532       0   100.00    0.00            10625   \n",
       "\n",
       "    Cum Goods  Cum Bads    FPR  % Good  % Bad(FDR)     KS  \n",
       "0          44       488   0.09    0.08       85.61  85.53  \n",
       "1         538       525   1.02    1.02       92.11  91.09  \n",
       "2        1067       527   2.02    2.03       92.46  90.43  \n",
       "3        1592       533   2.99    3.03       93.51  90.48  \n",
       "4        2123       534   3.98    4.04       93.68  89.64  \n",
       "5        2654       534   4.97    5.05       93.68  88.63  \n",
       "6        3184       535   5.95    6.06       93.86  87.80  \n",
       "7        3712       538   6.90    7.06       94.39  87.33  \n",
       "8        4242       539   7.87    8.07       94.56  86.49  \n",
       "9        4774       539   8.86    9.08       94.56  85.48  \n",
       "10       5299       545   9.72   10.08       95.61  85.53  \n",
       "11       5828       547  10.65   11.09       95.96  84.87  \n",
       "12       6357       549  11.58   12.10       96.32  84.22  \n",
       "13       6885       552  12.47   13.10       96.84  83.74  \n",
       "14       7417       552  13.44   14.11       96.84  82.73  \n",
       "15       7947       553  14.37   15.12       97.02  81.90  \n",
       "16       8478       553  15.33   16.13       97.02  80.89  \n",
       "17       9008       554  16.26   17.14       97.19  80.05  \n",
       "18       9538       555  17.19   18.15       97.37  79.22  \n",
       "19      10070       555  18.14   19.16       97.37  78.21  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Records</th>\n",
       "      <th># Bads</th>\n",
       "      <th># Goods</th>\n",
       "      <th>Fraud Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53125</td>\n",
       "      <td>570</td>\n",
       "      <td>52555</td>\n",
       "      <td>0.010729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   # Records  # Bads  # Goods  Fraud Rate\n",
       "0      53125     570    52555    0.010729"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_train=pd.DataFrame({'# Records':len(x_train),'# Bads': sum(y_train), '# Goods':len(x_train)-sum(y_train),\n",
    "                    'Fraud Rate': sum(y_train)/len(y_train)},index=[0])\n",
    "title_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test\n",
    "prop=0.2\n",
    "pred_test=model_rf.predict_proba(x_test)[:,1]\n",
    "result_test=pd.DataFrame({'Pred': pred_test, 'Fraud':y_test}).sort_values(by='Pred',ascending=False)\n",
    "result_test_part=result_test.head(round(len(x_test)*prop))\n",
    "    \n",
    "bin_df=pd.DataFrame(np.zeros(shape=(20,10)),columns=[\"Population\",\"# Records\",\"# Goods\",\"# Bads\",\"% Goods\",\"% Bads\",\n",
    "                                                   \"Total # Records\",\"Cum Goods\",\"Cum Bads\",\"FPR\"])\n",
    "cum_df=pd.DataFrame(np.zeros(shape=(20,3)),columns=[\"% Good\",\"% Bad(FDR)\",\"KS\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_qcut = result_test_part.copy().reset_index(drop=True).reset_index()\n",
    "bin_qcut['qcut_group'] = pd.qcut(bin_qcut['index'], 20,labels=False)\n",
    "population=range(1,21,1)\n",
    "bin_df[\"Population\"]=population\n",
    "n_records=bin_qcut.groupby('qcut_group').size()\n",
    "bin_df['# Records']=n_records\n",
    "n_bads=bin_qcut.groupby('qcut_group')['Fraud'].sum()\n",
    "bin_df['# Bads']=n_bads\n",
    "n_goods=n_records-n_bads\n",
    "bin_df['# Goods']=n_goods\n",
    "bin_df['% Goods']=round(n_goods/n_records*100,2)\n",
    "bin_df['% Bads']=round(n_bads/n_records*100,2)\n",
    "bin_df[\"Total # Records\"]=np.cumsum(n_records)  \n",
    "bin_df[\"Cum Goods\"]=np.cumsum(n_goods)\n",
    "bin_df[\"Cum Bads\"]=np.cumsum(n_bads)\n",
    "bin_df[\"FPR\"]=round(bin_df[\"Cum Goods\"]/bin_df[\"Cum Bads\"],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Population</th>\n",
       "      <th># Records</th>\n",
       "      <th># Goods</th>\n",
       "      <th># Bads</th>\n",
       "      <th>% Goods</th>\n",
       "      <th>% Bads</th>\n",
       "      <th>Total # Records</th>\n",
       "      <th>Cum Goods</th>\n",
       "      <th>Cum Bads</th>\n",
       "      <th>FPR</th>\n",
       "      <th>% Good</th>\n",
       "      <th>% Bad(FDR)</th>\n",
       "      <th>KS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>274</td>\n",
       "      <td>64</td>\n",
       "      <td>210</td>\n",
       "      <td>23.36</td>\n",
       "      <td>76.64</td>\n",
       "      <td>274</td>\n",
       "      <td>64</td>\n",
       "      <td>210</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.24</td>\n",
       "      <td>70.71</td>\n",
       "      <td>70.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>274</td>\n",
       "      <td>240</td>\n",
       "      <td>34</td>\n",
       "      <td>87.59</td>\n",
       "      <td>12.41</td>\n",
       "      <td>548</td>\n",
       "      <td>304</td>\n",
       "      <td>244</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.12</td>\n",
       "      <td>82.15</td>\n",
       "      <td>81.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>273</td>\n",
       "      <td>263</td>\n",
       "      <td>10</td>\n",
       "      <td>96.34</td>\n",
       "      <td>3.66</td>\n",
       "      <td>821</td>\n",
       "      <td>567</td>\n",
       "      <td>254</td>\n",
       "      <td>2.23</td>\n",
       "      <td>2.09</td>\n",
       "      <td>85.52</td>\n",
       "      <td>83.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>274</td>\n",
       "      <td>267</td>\n",
       "      <td>7</td>\n",
       "      <td>97.45</td>\n",
       "      <td>2.55</td>\n",
       "      <td>1095</td>\n",
       "      <td>834</td>\n",
       "      <td>261</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.08</td>\n",
       "      <td>87.88</td>\n",
       "      <td>84.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>274</td>\n",
       "      <td>271</td>\n",
       "      <td>3</td>\n",
       "      <td>98.91</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1369</td>\n",
       "      <td>1105</td>\n",
       "      <td>264</td>\n",
       "      <td>4.19</td>\n",
       "      <td>4.08</td>\n",
       "      <td>88.89</td>\n",
       "      <td>84.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>273</td>\n",
       "      <td>272</td>\n",
       "      <td>1</td>\n",
       "      <td>99.63</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1642</td>\n",
       "      <td>1377</td>\n",
       "      <td>265</td>\n",
       "      <td>5.20</td>\n",
       "      <td>5.09</td>\n",
       "      <td>89.23</td>\n",
       "      <td>84.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>274</td>\n",
       "      <td>271</td>\n",
       "      <td>3</td>\n",
       "      <td>98.91</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1916</td>\n",
       "      <td>1648</td>\n",
       "      <td>268</td>\n",
       "      <td>6.15</td>\n",
       "      <td>6.09</td>\n",
       "      <td>90.24</td>\n",
       "      <td>84.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>274</td>\n",
       "      <td>273</td>\n",
       "      <td>1</td>\n",
       "      <td>99.64</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2190</td>\n",
       "      <td>1921</td>\n",
       "      <td>269</td>\n",
       "      <td>7.14</td>\n",
       "      <td>7.09</td>\n",
       "      <td>90.57</td>\n",
       "      <td>83.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>273</td>\n",
       "      <td>272</td>\n",
       "      <td>1</td>\n",
       "      <td>99.63</td>\n",
       "      <td>0.37</td>\n",
       "      <td>2463</td>\n",
       "      <td>2193</td>\n",
       "      <td>270</td>\n",
       "      <td>8.12</td>\n",
       "      <td>8.10</td>\n",
       "      <td>90.91</td>\n",
       "      <td>82.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>274</td>\n",
       "      <td>274</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2737</td>\n",
       "      <td>2467</td>\n",
       "      <td>270</td>\n",
       "      <td>9.14</td>\n",
       "      <td>9.11</td>\n",
       "      <td>90.91</td>\n",
       "      <td>81.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>274</td>\n",
       "      <td>273</td>\n",
       "      <td>1</td>\n",
       "      <td>99.64</td>\n",
       "      <td>0.36</td>\n",
       "      <td>3011</td>\n",
       "      <td>2740</td>\n",
       "      <td>271</td>\n",
       "      <td>10.11</td>\n",
       "      <td>10.12</td>\n",
       "      <td>91.25</td>\n",
       "      <td>81.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>273</td>\n",
       "      <td>271</td>\n",
       "      <td>2</td>\n",
       "      <td>99.27</td>\n",
       "      <td>0.73</td>\n",
       "      <td>3284</td>\n",
       "      <td>3011</td>\n",
       "      <td>273</td>\n",
       "      <td>11.03</td>\n",
       "      <td>11.12</td>\n",
       "      <td>91.92</td>\n",
       "      <td>80.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>274</td>\n",
       "      <td>273</td>\n",
       "      <td>1</td>\n",
       "      <td>99.64</td>\n",
       "      <td>0.36</td>\n",
       "      <td>3558</td>\n",
       "      <td>3284</td>\n",
       "      <td>274</td>\n",
       "      <td>11.99</td>\n",
       "      <td>12.13</td>\n",
       "      <td>92.26</td>\n",
       "      <td>80.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>274</td>\n",
       "      <td>273</td>\n",
       "      <td>1</td>\n",
       "      <td>99.64</td>\n",
       "      <td>0.36</td>\n",
       "      <td>3832</td>\n",
       "      <td>3557</td>\n",
       "      <td>275</td>\n",
       "      <td>12.93</td>\n",
       "      <td>13.14</td>\n",
       "      <td>92.59</td>\n",
       "      <td>79.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>273</td>\n",
       "      <td>272</td>\n",
       "      <td>1</td>\n",
       "      <td>99.63</td>\n",
       "      <td>0.37</td>\n",
       "      <td>4105</td>\n",
       "      <td>3829</td>\n",
       "      <td>276</td>\n",
       "      <td>13.87</td>\n",
       "      <td>14.14</td>\n",
       "      <td>92.93</td>\n",
       "      <td>78.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>274</td>\n",
       "      <td>274</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4379</td>\n",
       "      <td>4103</td>\n",
       "      <td>276</td>\n",
       "      <td>14.87</td>\n",
       "      <td>15.16</td>\n",
       "      <td>92.93</td>\n",
       "      <td>77.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>274</td>\n",
       "      <td>274</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4653</td>\n",
       "      <td>4377</td>\n",
       "      <td>276</td>\n",
       "      <td>15.86</td>\n",
       "      <td>16.17</td>\n",
       "      <td>92.93</td>\n",
       "      <td>76.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>273</td>\n",
       "      <td>271</td>\n",
       "      <td>2</td>\n",
       "      <td>99.27</td>\n",
       "      <td>0.73</td>\n",
       "      <td>4926</td>\n",
       "      <td>4648</td>\n",
       "      <td>278</td>\n",
       "      <td>16.72</td>\n",
       "      <td>17.17</td>\n",
       "      <td>93.60</td>\n",
       "      <td>76.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>274</td>\n",
       "      <td>273</td>\n",
       "      <td>1</td>\n",
       "      <td>99.64</td>\n",
       "      <td>0.36</td>\n",
       "      <td>5200</td>\n",
       "      <td>4921</td>\n",
       "      <td>279</td>\n",
       "      <td>17.64</td>\n",
       "      <td>18.18</td>\n",
       "      <td>93.94</td>\n",
       "      <td>75.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>274</td>\n",
       "      <td>271</td>\n",
       "      <td>3</td>\n",
       "      <td>98.91</td>\n",
       "      <td>1.09</td>\n",
       "      <td>5474</td>\n",
       "      <td>5192</td>\n",
       "      <td>282</td>\n",
       "      <td>18.41</td>\n",
       "      <td>19.18</td>\n",
       "      <td>94.95</td>\n",
       "      <td>75.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Population  # Records  # Goods  # Bads  % Goods  % Bads  Total # Records  \\\n",
       "0            1        274       64     210    23.36   76.64              274   \n",
       "1            2        274      240      34    87.59   12.41              548   \n",
       "2            3        273      263      10    96.34    3.66              821   \n",
       "3            4        274      267       7    97.45    2.55             1095   \n",
       "4            5        274      271       3    98.91    1.09             1369   \n",
       "5            6        273      272       1    99.63    0.37             1642   \n",
       "6            7        274      271       3    98.91    1.09             1916   \n",
       "7            8        274      273       1    99.64    0.36             2190   \n",
       "8            9        273      272       1    99.63    0.37             2463   \n",
       "9           10        274      274       0   100.00    0.00             2737   \n",
       "10          11        274      273       1    99.64    0.36             3011   \n",
       "11          12        273      271       2    99.27    0.73             3284   \n",
       "12          13        274      273       1    99.64    0.36             3558   \n",
       "13          14        274      273       1    99.64    0.36             3832   \n",
       "14          15        273      272       1    99.63    0.37             4105   \n",
       "15          16        274      274       0   100.00    0.00             4379   \n",
       "16          17        274      274       0   100.00    0.00             4653   \n",
       "17          18        273      271       2    99.27    0.73             4926   \n",
       "18          19        274      273       1    99.64    0.36             5200   \n",
       "19          20        274      271       3    98.91    1.09             5474   \n",
       "\n",
       "    Cum Goods  Cum Bads    FPR  % Good  % Bad(FDR)     KS  \n",
       "0          64       210   0.30    0.24       70.71  70.47  \n",
       "1         304       244   1.25    1.12       82.15  81.03  \n",
       "2         567       254   2.23    2.09       85.52  83.43  \n",
       "3         834       261   3.20    3.08       87.88  84.80  \n",
       "4        1105       264   4.19    4.08       88.89  84.81  \n",
       "5        1377       265   5.20    5.09       89.23  84.14  \n",
       "6        1648       268   6.15    6.09       90.24  84.15  \n",
       "7        1921       269   7.14    7.09       90.57  83.48  \n",
       "8        2193       270   8.12    8.10       90.91  82.81  \n",
       "9        2467       270   9.14    9.11       90.91  81.80  \n",
       "10       2740       271  10.11   10.12       91.25  81.13  \n",
       "11       3011       273  11.03   11.12       91.92  80.80  \n",
       "12       3284       274  11.99   12.13       92.26  80.13  \n",
       "13       3557       275  12.93   13.14       92.59  79.45  \n",
       "14       3829       276  13.87   14.14       92.93  78.79  \n",
       "15       4103       276  14.87   15.16       92.93  77.77  \n",
       "16       4377       276  15.86   16.17       92.93  76.76  \n",
       "17       4648       278  16.72   17.17       93.60  76.43  \n",
       "18       4921       279  17.64   18.18       93.94  75.76  \n",
       "19       5192       282  18.41   19.18       94.95  75.77  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_test_bad=[]\n",
    "FDR_test_good=[]\n",
    "for p in population:\n",
    "    result_test_p=result_test.head(round(len(x_test)*p*0.01))\n",
    "    bad=sum(result_test_p.Fraud)/sum(y_test)\n",
    "    good=(len(result_test_p)-sum(result_test_p.Fraud))/(len(y_test)-sum(y_test))\n",
    "    FDR_test_bad.append(round(bad*100,2))\n",
    "    FDR_test_good.append(round(good*100,2))\n",
    "cum_df['% Bad(FDR)']= FDR_test_bad\n",
    "cum_df['% Good']=FDR_test_good\n",
    "cum_df['KS']=cum_df['% Bad(FDR)']-cum_df['% Good']\n",
    "test_table=pd.concat([bin_df,cum_df],axis=1)\n",
    "test_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Records</th>\n",
       "      <th># Bads</th>\n",
       "      <th># Goods</th>\n",
       "      <th>Fraud Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27368</td>\n",
       "      <td>297</td>\n",
       "      <td>27071</td>\n",
       "      <td>0.010852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   # Records  # Bads  # Goods  Fraud Rate\n",
       "0      27368     297    27071    0.010852"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_test=pd.DataFrame({'# Records':len(x_test),'# Bads': sum(y_test), '# Goods':len(x_test)-sum(y_test),\n",
    "                    'Fraud Rate': sum(y_test)/len(y_test)},index=[0])\n",
    "title_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_oot=oot.drop('Fraud',axis=1)\n",
    "y_oot=oot.Fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### oot\n",
    "prop=0.2\n",
    "pred_oot=model_rf.predict_proba(x_oot)[:,1]\n",
    "result_oot=pd.DataFrame({'Pred': pred_oot, 'Fraud':y_oot}).sort_values(by='Pred',ascending=False)\n",
    "result_oot_part=result_oot.head(round(len(x_oot)*prop))\n",
    "    \n",
    "bin_df=pd.DataFrame(np.zeros(shape=(20,10)),columns=[\"Population\",\"# Records\",\"# Goods\",\"# Bads\",\"% Goods\",\"% Bads\",\n",
    "                                                   \"Total # Records\",\"Cum Goods\",\"Cum Bads\",\"FPR\"])\n",
    "cum_df=pd.DataFrame(np.zeros(shape=(20,3)),columns=[\"% Good\",\"% Bad(FDR)\",\"KS\"])\n",
    "\n",
    "bin_qcut = result_oot_part.copy().reset_index(drop=True).reset_index()\n",
    "bin_qcut['qcut_group'] = pd.qcut(bin_qcut['index'], 20,labels=False)\n",
    "population=range(1,21,1)\n",
    "bin_df[\"Population\"]=population\n",
    "n_records=bin_qcut.groupby('qcut_group').size()\n",
    "bin_df['# Records']=n_records\n",
    "n_bads=bin_qcut.groupby('qcut_group')['Fraud'].sum()\n",
    "bin_df['# Bads']=n_bads\n",
    "n_goods=n_records-n_bads\n",
    "bin_df['# Goods']=n_goods\n",
    "bin_df['% Goods']=round(n_goods/n_records*100,2)\n",
    "bin_df['% Bads']=round(n_bads/n_records*100,2)\n",
    "bin_df[\"Total # Records\"]=np.cumsum(n_records)  \n",
    "bin_df[\"Cum Goods\"]=np.cumsum(n_goods)\n",
    "bin_df[\"Cum Bads\"]=np.cumsum(n_bads)\n",
    "bin_df[\"FPR\"]=round(bin_df[\"Cum Goods\"]/bin_df[\"Cum Bads\"],2)\n",
    "FDR_oot_bad=[]\n",
    "FDR_oot_good=[]\n",
    "for p in population:\n",
    "    result_oot_p=result_oot.head(round(len(x_oot)*p*0.01))\n",
    "    bad=sum(result_oot_p.Fraud)/sum(y_oot)\n",
    "    good=(len(result_oot_p)-sum(result_oot_p.Fraud))/(len(y_oot)-sum(y_oot))\n",
    "    FDR_oot_bad.append(round(bad*100,2))\n",
    "    FDR_oot_good.append(round(good*100,2))\n",
    "cum_df['% Bad(FDR)']= FDR_oot_bad\n",
    "cum_df['% Good']=FDR_oot_good\n",
    "cum_df['KS']=cum_df['% Bad(FDR)']-cum_df['% Good']\n",
    "oot_table=pd.concat([bin_df,cum_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Population</th>\n",
       "      <th># Records</th>\n",
       "      <th># Goods</th>\n",
       "      <th># Bads</th>\n",
       "      <th>% Goods</th>\n",
       "      <th>% Bads</th>\n",
       "      <th>Total # Records</th>\n",
       "      <th>Cum Goods</th>\n",
       "      <th>Cum Bads</th>\n",
       "      <th>FPR</th>\n",
       "      <th>% Good</th>\n",
       "      <th>% Bad(FDR)</th>\n",
       "      <th>KS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>43</td>\n",
       "      <td>82</td>\n",
       "      <td>34.40</td>\n",
       "      <td>65.60</td>\n",
       "      <td>125</td>\n",
       "      <td>43</td>\n",
       "      <td>82</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.34</td>\n",
       "      <td>45.81</td>\n",
       "      <td>45.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>124</td>\n",
       "      <td>115</td>\n",
       "      <td>9</td>\n",
       "      <td>92.74</td>\n",
       "      <td>7.26</td>\n",
       "      <td>249</td>\n",
       "      <td>158</td>\n",
       "      <td>91</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.29</td>\n",
       "      <td>50.84</td>\n",
       "      <td>49.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>124</td>\n",
       "      <td>106</td>\n",
       "      <td>18</td>\n",
       "      <td>85.48</td>\n",
       "      <td>14.52</td>\n",
       "      <td>373</td>\n",
       "      <td>264</td>\n",
       "      <td>109</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.16</td>\n",
       "      <td>60.89</td>\n",
       "      <td>58.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>124</td>\n",
       "      <td>116</td>\n",
       "      <td>8</td>\n",
       "      <td>93.55</td>\n",
       "      <td>6.45</td>\n",
       "      <td>497</td>\n",
       "      <td>380</td>\n",
       "      <td>117</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.10</td>\n",
       "      <td>65.36</td>\n",
       "      <td>62.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>125</td>\n",
       "      <td>121</td>\n",
       "      <td>4</td>\n",
       "      <td>96.80</td>\n",
       "      <td>3.20</td>\n",
       "      <td>622</td>\n",
       "      <td>501</td>\n",
       "      <td>121</td>\n",
       "      <td>4.14</td>\n",
       "      <td>4.08</td>\n",
       "      <td>67.60</td>\n",
       "      <td>63.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>124</td>\n",
       "      <td>122</td>\n",
       "      <td>2</td>\n",
       "      <td>98.39</td>\n",
       "      <td>1.61</td>\n",
       "      <td>746</td>\n",
       "      <td>623</td>\n",
       "      <td>123</td>\n",
       "      <td>5.07</td>\n",
       "      <td>5.09</td>\n",
       "      <td>68.72</td>\n",
       "      <td>63.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>124</td>\n",
       "      <td>122</td>\n",
       "      <td>2</td>\n",
       "      <td>98.39</td>\n",
       "      <td>1.61</td>\n",
       "      <td>870</td>\n",
       "      <td>745</td>\n",
       "      <td>125</td>\n",
       "      <td>5.96</td>\n",
       "      <td>6.08</td>\n",
       "      <td>69.83</td>\n",
       "      <td>63.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>994</td>\n",
       "      <td>869</td>\n",
       "      <td>125</td>\n",
       "      <td>6.95</td>\n",
       "      <td>7.10</td>\n",
       "      <td>69.83</td>\n",
       "      <td>62.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1118</td>\n",
       "      <td>993</td>\n",
       "      <td>125</td>\n",
       "      <td>7.94</td>\n",
       "      <td>8.11</td>\n",
       "      <td>69.83</td>\n",
       "      <td>61.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>125</td>\n",
       "      <td>121</td>\n",
       "      <td>4</td>\n",
       "      <td>96.80</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1243</td>\n",
       "      <td>1114</td>\n",
       "      <td>129</td>\n",
       "      <td>8.64</td>\n",
       "      <td>9.10</td>\n",
       "      <td>72.07</td>\n",
       "      <td>62.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>124</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>99.19</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1367</td>\n",
       "      <td>1237</td>\n",
       "      <td>130</td>\n",
       "      <td>9.52</td>\n",
       "      <td>10.10</td>\n",
       "      <td>72.63</td>\n",
       "      <td>62.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>124</td>\n",
       "      <td>120</td>\n",
       "      <td>4</td>\n",
       "      <td>96.77</td>\n",
       "      <td>3.23</td>\n",
       "      <td>1491</td>\n",
       "      <td>1357</td>\n",
       "      <td>134</td>\n",
       "      <td>10.13</td>\n",
       "      <td>11.08</td>\n",
       "      <td>74.86</td>\n",
       "      <td>63.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>124</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>99.19</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1615</td>\n",
       "      <td>1480</td>\n",
       "      <td>135</td>\n",
       "      <td>10.96</td>\n",
       "      <td>12.09</td>\n",
       "      <td>75.42</td>\n",
       "      <td>63.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1739</td>\n",
       "      <td>1604</td>\n",
       "      <td>135</td>\n",
       "      <td>11.88</td>\n",
       "      <td>13.10</td>\n",
       "      <td>75.42</td>\n",
       "      <td>62.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1864</td>\n",
       "      <td>1729</td>\n",
       "      <td>135</td>\n",
       "      <td>12.81</td>\n",
       "      <td>14.12</td>\n",
       "      <td>75.42</td>\n",
       "      <td>61.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>124</td>\n",
       "      <td>122</td>\n",
       "      <td>2</td>\n",
       "      <td>98.39</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1988</td>\n",
       "      <td>1851</td>\n",
       "      <td>137</td>\n",
       "      <td>13.51</td>\n",
       "      <td>15.11</td>\n",
       "      <td>76.54</td>\n",
       "      <td>61.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>124</td>\n",
       "      <td>122</td>\n",
       "      <td>2</td>\n",
       "      <td>98.39</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2112</td>\n",
       "      <td>1973</td>\n",
       "      <td>139</td>\n",
       "      <td>14.19</td>\n",
       "      <td>16.12</td>\n",
       "      <td>77.65</td>\n",
       "      <td>61.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>124</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>99.19</td>\n",
       "      <td>0.81</td>\n",
       "      <td>2236</td>\n",
       "      <td>2096</td>\n",
       "      <td>140</td>\n",
       "      <td>14.97</td>\n",
       "      <td>17.12</td>\n",
       "      <td>78.21</td>\n",
       "      <td>61.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2360</td>\n",
       "      <td>2220</td>\n",
       "      <td>140</td>\n",
       "      <td>15.86</td>\n",
       "      <td>18.13</td>\n",
       "      <td>78.21</td>\n",
       "      <td>60.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>125</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "      <td>99.20</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2485</td>\n",
       "      <td>2344</td>\n",
       "      <td>141</td>\n",
       "      <td>16.62</td>\n",
       "      <td>19.14</td>\n",
       "      <td>78.77</td>\n",
       "      <td>59.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Population  # Records  # Goods  # Bads  % Goods  % Bads  Total # Records  \\\n",
       "0            1        125       43      82    34.40   65.60              125   \n",
       "1            2        124      115       9    92.74    7.26              249   \n",
       "2            3        124      106      18    85.48   14.52              373   \n",
       "3            4        124      116       8    93.55    6.45              497   \n",
       "4            5        125      121       4    96.80    3.20              622   \n",
       "5            6        124      122       2    98.39    1.61              746   \n",
       "6            7        124      122       2    98.39    1.61              870   \n",
       "7            8        124      124       0   100.00    0.00              994   \n",
       "8            9        124      124       0   100.00    0.00             1118   \n",
       "9           10        125      121       4    96.80    3.20             1243   \n",
       "10          11        124      123       1    99.19    0.81             1367   \n",
       "11          12        124      120       4    96.77    3.23             1491   \n",
       "12          13        124      123       1    99.19    0.81             1615   \n",
       "13          14        124      124       0   100.00    0.00             1739   \n",
       "14          15        125      125       0   100.00    0.00             1864   \n",
       "15          16        124      122       2    98.39    1.61             1988   \n",
       "16          17        124      122       2    98.39    1.61             2112   \n",
       "17          18        124      123       1    99.19    0.81             2236   \n",
       "18          19        124      124       0   100.00    0.00             2360   \n",
       "19          20        125      124       1    99.20    0.80             2485   \n",
       "\n",
       "    Cum Goods  Cum Bads    FPR  % Good  % Bad(FDR)     KS  \n",
       "0          43        82   0.52    0.34       45.81  45.47  \n",
       "1         158        91   1.74    1.29       50.84  49.55  \n",
       "2         264       109   2.42    2.16       60.89  58.73  \n",
       "3         380       117   3.25    3.10       65.36  62.26  \n",
       "4         501       121   4.14    4.08       67.60  63.52  \n",
       "5         623       123   5.07    5.09       68.72  63.63  \n",
       "6         745       125   5.96    6.08       69.83  63.75  \n",
       "7         869       125   6.95    7.10       69.83  62.73  \n",
       "8         993       125   7.94    8.11       69.83  61.72  \n",
       "9        1114       129   8.64    9.10       72.07  62.97  \n",
       "10       1237       130   9.52   10.10       72.63  62.53  \n",
       "11       1357       134  10.13   11.08       74.86  63.78  \n",
       "12       1480       135  10.96   12.09       75.42  63.33  \n",
       "13       1604       135  11.88   13.10       75.42  62.32  \n",
       "14       1729       135  12.81   14.12       75.42  61.30  \n",
       "15       1851       137  13.51   15.11       76.54  61.43  \n",
       "16       1973       139  14.19   16.12       77.65  61.53  \n",
       "17       2096       140  14.97   17.12       78.21  61.09  \n",
       "18       2220       140  15.86   18.13       78.21  60.08  \n",
       "19       2344       141  16.62   19.14       78.77  59.63  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Records</th>\n",
       "      <th># Bads</th>\n",
       "      <th># Goods</th>\n",
       "      <th>Fraud Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12427</td>\n",
       "      <td>179</td>\n",
       "      <td>12248</td>\n",
       "      <td>0.014404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   # Records  # Bads  # Goods  Fraud Rate\n",
       "0      12427     179    12248    0.014404"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_oot=pd.DataFrame({'# Records':len(x_oot),'# Bads': sum(y_oot), '# Goods':len(x_oot)-sum(y_oot),\n",
    "                    'Fraud Rate': sum(y_oot)/len(y_oot)},index=[0])\n",
    "title_oot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Fraud Savings Calculation Suggests Score Cutoff\n",
    "\n",
    "Assume $2000 gain for every fraud that’s caught (blue curve)\n",
    "\n",
    "Assume $50 loss for every false positive (good that’s flagged as a bad) (red)\n",
    "\n",
    "Calculate the Fraud Savings, Lost Sales, Overall Savings (green), and make a recommendation for where the client should set a score cutoff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename=\"Capture.PNG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4% and 5% don't have a large difference. To satisfy customers, we choose 4% as the cutoff, which will generate the overall saving of 215000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
